{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: latin-1 -*-\n",
    "import pandas as pd # pandas is a data manipulation library\n",
    "import numpy as np #provides numerical arrays and functions to manipulate the arrays efficiently\n",
    "import logging\n",
    "import difflib\n",
    "import Levenshtein as lev\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import re\n",
    "import movies_df_helper_functions as helper_fn\n",
    "import evaluation_helper_functions as eval_fn\n",
    "import random\n",
    "import imp\n",
    "import itertools\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import html\n",
    "import csv\n",
    "import re\n",
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "from tabulate import tabulate\n",
    "import decimal\n",
    "from collections import Counter\n",
    "\n",
    "imp.reload(eval_fn)\n",
    "imp.reload(helper_fn)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data\n",
    "#train_data_df = pd.read_csv('models/baseline_exp/train_data.csv')\n",
    "train_data_df = pd.read_csv('train_data/train_data.csv')\n",
    "#load genres test data\n",
    "genres_sample_df = pd.read_csv('test_data/genres_sample_movies_id_list.csv')\n",
    "#load all genres lists df\n",
    "genres_df = pd.read_csv('test_data/movies_by_genre.csv')\n",
    "#load all sequel and mixed data for plotting\n",
    "sequel_sampled_data_df = pd.read_csv('test_data/sequel_and_sampled_titles_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'baseline-exp/model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-82d2da1c6ebb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#load model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'baseline-exp/model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \"\"\"\n\u001b[0;32m    856\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model saved using code from earlier Gensim Version. Re-loading old model in a compatible way.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \"\"\"\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseWordEmbeddingsModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ns_exponent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mns_exponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \"\"\"\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseAny2VecModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m     \"\"\"\n\u001b[1;32m-> 1395\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1396\u001b[0m         \u001b[1;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     fobj = _shortcut_open(\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, ignore_ext, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'baseline-exp/model'"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "model = Doc2Vec.load('baseline-exp/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_genre(genre_df, movie_id):\n",
    "    romantic_comedy= genre_df.romantic_comedy.values.tolist()\n",
    "    drama = genre_df.drama.values.tolist()\n",
    "    adventure = genre_df.adventure.values.tolist()\n",
    "    crime = genre_df.crime.values.tolist()\n",
    "    action = genre_df.action.values.tolist()\n",
    "    \n",
    "    if movie_id in romantic_comedy:\n",
    "        return 'Romantic_Comedy'\n",
    "    else:\n",
    "        if movie_id in drama:\n",
    "            return 'Drama'\n",
    "        else: \n",
    "            if movie_id in adventure:\n",
    "                return 'Adventure'\n",
    "            else: \n",
    "                if movie_id in crime:\n",
    "                    return 'Crime'\n",
    "                else: \n",
    "                    if movie_id in action: return 'Action'\n",
    "                    else: \n",
    "                        return 'Unkown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean train_data_df\n",
    "#remove the square brackets saved when generating the test data.It i snot a bug. Data can't be saved without as they act as a column separator in the csv file\n",
    "train_data_df['actor_name'] = train_data_df.actor_name.apply(lambda actor: actor.replace('[','').replace(']','').replace(\"'\", \"\") )\n",
    "train_data_df['director_name'] = train_data_df.director_name.apply(lambda director: director.replace('[','').replace(']','').replace(\"'\", \"\") )\n",
    "train_data_df['writer_name'] = train_data_df.writer_name.apply(lambda writer: writer.replace('[','').replace(']','').replace(\"'\", \"\") )\n",
    "train_data_df['country'] = train_data_df.country.apply(lambda country: country.replace('[','').replace(']','').replace(\"'\", \"\") )\n",
    "train_data_df['genre'] = train_data_df.genre.apply(lambda genre: genre.replace('[','').replace(']','').replace(\"'\", \"\") )\n",
    "\n",
    "train_data_df['actor_name'] = train_data_df.actor_name.apply(lambda actor: actor.split(',') )\n",
    "train_data_df['director_name'] = train_data_df.director_name.apply(lambda director: director.split(',') )\n",
    "train_data_df['writer_name'] = train_data_df.writer_name.apply(lambda writer: writer.split(',') )\n",
    "train_data_df['country'] = train_data_df.country.apply(lambda country: country.split(',') )\n",
    "train_data_df['genre'] = train_data_df.genre.apply(lambda genre: genre.split(',') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['agony_(film)', 'agony',\n",
       "        list(['anatoli_romashin', 'alisa_freindlich', 'velta_līne', 'alexei_petrenko']),\n",
       "        list(['elem_klimov']), list(['semyon_lungin', 'ilya_nusinov']),\n",
       "        list(['russian_soviet_federative_socialist_republic', 'soviet_union']),\n",
       "        list(['political_drama', 'biographical_film', 'historical_film_q17013749']),\n",
       "        \"['velta_līne', 'elem_klimov', 'alexei_petrenko', 'anatoli_romashin', 'biographical_film', 'soviet_union', 'historical_film_q17013749', 'ilya_nusinov', 'semyon_lungin', 'political_drama', 'russian_soviet_federative_socialist_republic', 'alisa_freindlich']\"]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df['actor_name'] = train_data_df.actor_name.apply(lambda actor: [a.strip() for a in actor])\n",
    "train_data_df['director_name'] = train_data_df.director_name.apply(lambda director: [d.strip() for d in director])\n",
    "train_data_df['writer_name'] = train_data_df.writer_name.apply(lambda writer: [w.strip() for w in writer] )\n",
    "train_data_df['country'] = train_data_df.country.apply(lambda country: [c.strip() for c in country] )\n",
    "train_data_df['genre'] = train_data_df.genre.apply(lambda genre: [g.strip() for g in genre])\n",
    "\n",
    "\n",
    "train_data_df[train_data_df['movie_id'] == 'agony_(film)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>director_name</th>\n",
       "      <th>writer_name</th>\n",
       "      <th>country</th>\n",
       "      <th>genre</th>\n",
       "      <th>movie_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'68_(film)</td>\n",
       "      <td>'68</td>\n",
       "      <td>[jan_němec, neil_young]</td>\n",
       "      <td>[steven_kovacs]</td>\n",
       "      <td>[steven_kovacs]</td>\n",
       "      <td>[united_states]</td>\n",
       "      <td>[lgbt-related_film_q20442589]</td>\n",
       "      <td>['lgbt-related_film_q20442589', 'jan_němec', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'71_(film)</td>\n",
       "      <td>'71</td>\n",
       "      <td>[richard_dormer, charlie_murphy_, sean_harris,...</td>\n",
       "      <td>[yann_demange]</td>\n",
       "      <td>[gregory_burke]</td>\n",
       "      <td>[united_kingdom]</td>\n",
       "      <td>[crime_film, thriller_film, war_film, action_f...</td>\n",
       "      <td>['gregory_burke', 'action_film', 'crime_film',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'gator_bait</td>\n",
       "      <td>'gator bait</td>\n",
       "      <td>[claudia_jennings]</td>\n",
       "      <td>[beverly_sebastion]</td>\n",
       "      <td>[beverly_sebastion]</td>\n",
       "      <td>[united_states]</td>\n",
       "      <td>[thriller_film, action_film]</td>\n",
       "      <td>['action_film', 'claudia_jennings', 'thriller_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'neath_the_arizona_skies</td>\n",
       "      <td>'neath the arizona skies</td>\n",
       "      <td>[john_wayne, sheila_terry]</td>\n",
       "      <td>[harry_l._fraser]</td>\n",
       "      <td>[burl_r._tuttle]</td>\n",
       "      <td>[united_states]</td>\n",
       "      <td>[b_movies_]</td>\n",
       "      <td>['b_movies_', 'john_wayne', 'burl_r._tuttle', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'r_xmas</td>\n",
       "      <td>'r xmas</td>\n",
       "      <td>[andrew_fiscella, victor_argo, ice-t, drea_de_...</td>\n",
       "      <td>[abel_ferrara]</td>\n",
       "      <td>[abel_ferrara]</td>\n",
       "      <td>[united_states]</td>\n",
       "      <td>[christmas_film_q28026639, crime_film]</td>\n",
       "      <td>['crime_film', 'lillo_brancato', 'christmas_fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19487</th>\n",
       "      <td>zouzou_(film)</td>\n",
       "      <td>zouzou</td>\n",
       "      <td>[jean_gabin, josephine_baker]</td>\n",
       "      <td>[marc_allégret]</td>\n",
       "      <td>[carlo_rim]</td>\n",
       "      <td>[france]</td>\n",
       "      <td>[musical_film]</td>\n",
       "      <td>['marc_allégret', 'josephine_baker', 'jean_gab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19488</th>\n",
       "      <td>zubeidaa</td>\n",
       "      <td>zubeidaa</td>\n",
       "      <td>[rekha, karisma_kapoor, farida_jalal, amrish_p...</td>\n",
       "      <td>[shyam_benegal]</td>\n",
       "      <td>[khalid_mohamed]</td>\n",
       "      <td>[india]</td>\n",
       "      <td>[romance_film]</td>\n",
       "      <td>['farida_jalal', 'rekha', 'romance_film', 'amr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19489</th>\n",
       "      <td>zulu_(1964_film)</td>\n",
       "      <td>zulu</td>\n",
       "      <td>[ulla_jacobsson, stanley_baker, james_booth, m...</td>\n",
       "      <td>[cy_endfield]</td>\n",
       "      <td>[john_prebble, cy_endfield]</td>\n",
       "      <td>[united_kingdom]</td>\n",
       "      <td>[adventure_film, war_film]</td>\n",
       "      <td>['john_prebble', 'jack_hawkins', 'michael_cain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19490</th>\n",
       "      <td>zulu_(2013_film)</td>\n",
       "      <td>zulu</td>\n",
       "      <td>[forest_whitaker, orlando_bloom]</td>\n",
       "      <td>[jérôme_salle]</td>\n",
       "      <td>[jérôme_salle]</td>\n",
       "      <td>[france]</td>\n",
       "      <td>[crime_film]</td>\n",
       "      <td>['crime_film', 'forest_whitaker', 'jérôme_sall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19491</th>\n",
       "      <td>zus_&amp;_zo</td>\n",
       "      <td>zus &amp; zo</td>\n",
       "      <td>[monic_hendrickx, jacob_derwig, halina_reijn]</td>\n",
       "      <td>[paula_van_der_oest]</td>\n",
       "      <td>[paula_van_der_oest]</td>\n",
       "      <td>[netherlands]</td>\n",
       "      <td>[romantic_comedy]</td>\n",
       "      <td>['monic_hendrickx', 'paula_van_der_oest', 'hal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19492 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       movie_id                     title  \\\n",
       "0                    '68_(film)                       '68   \n",
       "1                    '71_(film)                       '71   \n",
       "2                   'gator_bait               'gator bait   \n",
       "3      'neath_the_arizona_skies  'neath the arizona skies   \n",
       "4                       'r_xmas                   'r xmas   \n",
       "...                         ...                       ...   \n",
       "19487             zouzou_(film)                    zouzou   \n",
       "19488                  zubeidaa                  zubeidaa   \n",
       "19489          zulu_(1964_film)                      zulu   \n",
       "19490          zulu_(2013_film)                      zulu   \n",
       "19491                  zus_&_zo                  zus & zo   \n",
       "\n",
       "                                              actor_name  \\\n",
       "0                                [jan_němec, neil_young]   \n",
       "1      [richard_dormer, charlie_murphy_, sean_harris,...   \n",
       "2                                     [claudia_jennings]   \n",
       "3                             [john_wayne, sheila_terry]   \n",
       "4      [andrew_fiscella, victor_argo, ice-t, drea_de_...   \n",
       "...                                                  ...   \n",
       "19487                      [jean_gabin, josephine_baker]   \n",
       "19488  [rekha, karisma_kapoor, farida_jalal, amrish_p...   \n",
       "19489  [ulla_jacobsson, stanley_baker, james_booth, m...   \n",
       "19490                   [forest_whitaker, orlando_bloom]   \n",
       "19491      [monic_hendrickx, jacob_derwig, halina_reijn]   \n",
       "\n",
       "              director_name                  writer_name           country  \\\n",
       "0           [steven_kovacs]              [steven_kovacs]   [united_states]   \n",
       "1            [yann_demange]              [gregory_burke]  [united_kingdom]   \n",
       "2       [beverly_sebastion]          [beverly_sebastion]   [united_states]   \n",
       "3         [harry_l._fraser]             [burl_r._tuttle]   [united_states]   \n",
       "4            [abel_ferrara]               [abel_ferrara]   [united_states]   \n",
       "...                     ...                          ...               ...   \n",
       "19487       [marc_allégret]                  [carlo_rim]          [france]   \n",
       "19488       [shyam_benegal]             [khalid_mohamed]           [india]   \n",
       "19489         [cy_endfield]  [john_prebble, cy_endfield]  [united_kingdom]   \n",
       "19490        [jérôme_salle]               [jérôme_salle]          [france]   \n",
       "19491  [paula_van_der_oest]         [paula_van_der_oest]     [netherlands]   \n",
       "\n",
       "                                                   genre  \\\n",
       "0                          [lgbt-related_film_q20442589]   \n",
       "1      [crime_film, thriller_film, war_film, action_f...   \n",
       "2                           [thriller_film, action_film]   \n",
       "3                                            [b_movies_]   \n",
       "4                 [christmas_film_q28026639, crime_film]   \n",
       "...                                                  ...   \n",
       "19487                                     [musical_film]   \n",
       "19488                                     [romance_film]   \n",
       "19489                         [adventure_film, war_film]   \n",
       "19490                                       [crime_film]   \n",
       "19491                                  [romantic_comedy]   \n",
       "\n",
       "                                          movie_sentence  \n",
       "0      ['lgbt-related_film_q20442589', 'jan_němec', '...  \n",
       "1      ['gregory_burke', 'action_film', 'crime_film',...  \n",
       "2      ['action_film', 'claudia_jennings', 'thriller_...  \n",
       "3      ['b_movies_', 'john_wayne', 'burl_r._tuttle', ...  \n",
       "4      ['crime_film', 'lillo_brancato', 'christmas_fi...  \n",
       "...                                                  ...  \n",
       "19487  ['marc_allégret', 'josephine_baker', 'jean_gab...  \n",
       "19488  ['farida_jalal', 'rekha', 'romance_film', 'amr...  \n",
       "19489  ['john_prebble', 'jack_hawkins', 'michael_cain...  \n",
       "19490  ['crime_film', 'forest_whitaker', 'jérôme_sall...  \n",
       "19491  ['monic_hendrickx', 'paula_van_der_oest', 'hal...  \n",
       "\n",
       "[19492 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary with the movie_id and title\n",
    "movies_dict= dict(zip(train_data_df.movie_id, train_data_df.title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e4fc7a66b3dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#movie_id=\"blade:_trinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0msimilar_movies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0msim_movies_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msimilar_movies\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, indexer)\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1727\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1728\u001b[1;33m             \u001b[1;32melif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoctags\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1729\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_docs_norm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_int_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoctags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1730\u001b[0m                 \u001b[0mall_docs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_int_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoctags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "#Manual check\n",
    "#movie_id = 'godzilla_vs._biollante'\n",
    "#movie_id = 'the_bunker_(2001_film)'\n",
    "#movie_id= 'just_go_with_it'\n",
    "#movie_id='agony_(film)'\n",
    "#movie_id= 'harry_potter_and_the_half-blood_prince_(film)'\n",
    "#movie_id = 'toy_story_4'\n",
    "#movie_id = 'tsar_(film)'\n",
    "#movie_id='high_school_musical_3:_senior_year'\n",
    "#movie_id= 'hook_(film)'\n",
    "#movie_id=\"destiny_(1997_film)\"\n",
    "#movie_id=\"blade:_trinity\"\n",
    "\n",
    "\n",
    "similar_movies = model.docvecs.most_similar(movie_id, topn=10)\n",
    "sim_movies_list = [sim[0] for sim in similar_movies]\n",
    "\n",
    "sim_df= pd.DataFrame(columns=['Title','Similarity Ratio'])\n",
    "\n",
    "for sim in similar_movies:\n",
    "    #title = helper_fn.find_movie_title_by_id(sim[0], train_data_df)\n",
    "    data = {'Title':  [sim[0]],'Similarity Ratio': [sim[1]]}\n",
    "    tmp_df = pd.DataFrame(data, columns=['Title','Similarity Ratio'])\n",
    "    sim_df = pd.concat([sim_df, tmp_df])   \n",
    "\n",
    "common_features_df = eval_fn.get_common_attrs_cnt_for_sim_list(train_data_df, sim_movies_list, movie_id) \n",
    "\n",
    "result_df = sim_df.merge(common_features_df, left_on= ['Title'], right_on=['Title'], how='inner')\n",
    "\n",
    "result_df.Title= result_df.Title.map(lambda t: (helper_fn.find_movie_title_by_id(t, train_data_df).values[0]).capitalize())\n",
    "\n",
    "query_movie_title = helper_fn.find_movie_title_by_id(movie_id, train_data_df).values[0].capitalize()\n",
    "print(\"\\n\")\n",
    "print(\"Similarity for the movie title \\\"{}\\\"\".format(query_movie_title))\n",
    "display(tabulate(result_df, headers=result_df.columns,tablefmt='html', showindex=False))\n",
    "\n",
    "#sim = docs_vectors.most_similar(positive= 'harry_potter_and_the_chamber_of_secrets_(film)', topn= 5)\n",
    "#eval_fn.print_sim_list(similar_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fn.find_common_attrs(train_data_df, movie_id, 'blade_(film)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the count of every feature\n",
    "sim_movies_deails_df = train_data_df.loc[train_data_df.apply(lambda movie: True if movie.movie_id in sim_movies_list else False, axis=1)]\n",
    "\n",
    "sim_movies_deails_df.apply(lambda movie: len(movie.actor_name), axis=1)\n",
    "\n",
    "movie_record = train_data_df[train_data_df.movie_id == movie_id]\n",
    "\n",
    "def find_feature_cnt_for_movie(movie_record, col):\n",
    "    col_list = movie_record[col].to_list()\n",
    "    if col_list is not None:\n",
    "        return len(col_list[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "actors = find_feature_cnt_for_movie(movie_record, 'actor_name')\n",
    "\n",
    "actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in similar_movies:\n",
    "    print(s[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data from the same movies used in the manual check\n",
    "test_movies_list= ['godzilla_vs._biollante'\n",
    "        ,'the_bunker_(2001_film)'\n",
    "        ,'just_go_with_it'\n",
    "        ,'agony_(film)'\n",
    "        ,'harry_potter_and_the_half-blood_prince_(film)'\n",
    "        ,'toy_story_4'\n",
    "        ,'tsar_(film)'\n",
    "        ,'high_school_musical_3:_senior_year'\n",
    "        , 'hook_(film)'\n",
    "        ,\"destiny_(1997_film)\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query each movie for most similar list\n",
    "#save each query movie and the result in a dictionary\n",
    "#for each group, retrieve actors for all the movies in the list\n",
    "\n",
    "group_by_q_movie=[]\n",
    "all_groups_actors=[]\n",
    "for movie_id in test_movies_list:\n",
    "    sims= model.docvecs.most_similar(movie_id,topn=5)\n",
    "    g_movies=[]\n",
    "    for s in sims:\n",
    "        g_movies.append(s[0])\n",
    "    group = {'g_id':movie_id, 'g_movies':g_movies}\n",
    "    group_by_q_movie.append(group)\n",
    "    \n",
    "    \n",
    "for group in group_by_q_movie:\n",
    "    query_movie_id = group['g_id']\n",
    "    sim_movies_id_list = group['g_movies']\n",
    "    group_actors=[]\n",
    "    group_movies=[]\n",
    "    actors = helper_fn.find_actors_by_movie_id(query_movie_id, train_data_df)\n",
    "    \n",
    "    group_actors = group_actors + actors[0]\n",
    "    #print(group_actors)\n",
    "    group_movies.append(query_movie_id)    \n",
    "   # print(\"group ID {}\".format(query_movie_id))\n",
    "    \n",
    "    for movie_id in sim_movies_id_list:\n",
    "        #print(\"sim movie id {} :\".format(movie_id))\n",
    "        actors = helper_fn.find_actors_by_movie_id(movie_id, train_data_df)\n",
    "        group_actors = group_actors + actors[0]\n",
    "        group_movies.append(movie_id)\n",
    "        #print(group_actors)\n",
    "    all_groups_actors.append({'g_id':query_movie_id, 'g_movies':group_movies, 'g_actors':group_actors})\n",
    "\n",
    "\n",
    "group_actors_df = pd.DataFrame(data= {'movie_id':[g['g_id'] for g in all_groups_actors], \n",
    "                'movies_list':[g['g_movies'] for g in all_groups_actors],\n",
    "               'actors_list':[g['g_actors'] for g in all_groups_actors]\n",
    "               })\n",
    "\n",
    "\n",
    "#display(group_actors_df)\n",
    "\n",
    "data_target_list=[]\n",
    "movies_target_list=[]\n",
    "actors_target_list=[]\n",
    "\n",
    "for group in all_groups_actors:\n",
    "    movies_target_list = movies_target_list + list(itertools.product([group['g_id']], group['g_movies']))\n",
    "print(len(movies_target_list))\n",
    "x_movies_df= pd.DataFrame(data= list(set(movies_target_list)), columns=['Y','X'])\n",
    "x_movies_df['type']= 'movie'\n",
    "\n",
    "    \n",
    "for group in all_groups_actors:\n",
    "    actors_target_list = actors_target_list + list(itertools.product([group['g_id']], group['g_actors']))\n",
    "print(len(actors_target_list))\n",
    "x_actors_df= pd.DataFrame(data= list(set(actors_target_list)), columns=['Y','X'])\n",
    "x_actors_df['type']= 'actor'\n",
    "\n",
    "final_df = x_actors_df.append(x_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Visualization\n",
    "print(len(final_df))\n",
    "\n",
    "final_df.reset_index(drop=True, inplace= True)\n",
    "y=[]\n",
    "data_X = []\n",
    "type_x =[]\n",
    "final_df['title']= final_df.apply(lambda row: helper_fn.find_movie_title_by_id(row.Y,train_data_df).values[0], axis=1)\n",
    "final_df['title'] = final_df['title'].str.capitalize()\n",
    "#y_vec = [model[tag] for tag in y]\n",
    "\n",
    "doctags= model.docvecs.doctags\n",
    "vocab = model.wv.vocab\n",
    "final_df = final_df.sample(frac=1)\n",
    "plt.rcParams[\"figure.figsize\"] = [8,6]\n",
    "data_X_vec=[]\n",
    "for tag in final_df['X'].values :                \n",
    "    if tag in doctags:\n",
    "        tag_vec= model[tag] \n",
    "    else:\n",
    "        if tag in vocab:\n",
    "            tag_vec= model.wv[tag] \n",
    "        else:\n",
    "            tag_vec=[0]*50\n",
    "    data_X_vec.append(tag_vec)\n",
    "final_df['X_vec']=data_X_vec\n",
    "\n",
    "tsne=  TSNE(perplexity= 50, n_components=2, init='pca', n_iter=7000, random_state=23)\n",
    "\n",
    "tsne_obj= tsne.fit_transform(final_df.X_vec.to_list())\n",
    "\n",
    "tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                        'Y':tsne_obj[:,1],\n",
    "                        'movie':final_df.title.to_list(),\n",
    "                         'X_type':final_df.type.to_list()})\n",
    "\n",
    "#sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "\n",
    "#movies_only=tsne_df[tsne_df['X_type']=='actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "palette=['purple','red','orange','brown','blue','dodgerblue','green','lightgreen','darkcyan', 'black']\n",
    "g = sns.scatterplot(x=\"X\", y=\"Y\", data=tsne_df, palette= palette, hue=\"movie\");\n",
    "\n",
    "tsne_df.apply(lambda point: g.scatter(point['X'], point['Y'], marker=find_marker(point['X_type'])), axis=1)\n",
    "\n",
    "              \n",
    "\n",
    "\n",
    "\n",
    "g.legend(loc='center left', bbox_to_anchor=(1.00, 0.5), ncol=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_marker(type_X):\n",
    "    if type_X == 'movie':\n",
    "        return \"o\"\n",
    "    else:\n",
    "        if type_X == 'actor':\n",
    "            return \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id='agony_(film)'\n",
    "sims= model.docvecs.most_similar(movie_id,topn=5)\n",
    "eval_fn.calculate_BLEU_score(movie_id, sims,train_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visialize movies grouped by the query movie_id- for each movie in the test set, generate the sim list and save them in a dict with the query movie as the key\n",
    "#for each group, plot the query movie and the sim list using distinct color\n",
    "#generate similarity list for each movie in the test set\n",
    "vis_group_by_q_movie=[]\n",
    "for movie_id in test_movies_list:\n",
    "    sims= model.docvecs.most_similar(movie_id)\n",
    "    g_movies=[]\n",
    "    for s in sims:\n",
    "        g_movies.append(s[0])\n",
    "    group = {'g_id':movie_id, 'g_movies':g_movies}\n",
    "    vis_group_by_q_movie.append(group)\n",
    "#print(vis_group_by_q_movie)    \n",
    "\n",
    "data_target_list=[]\n",
    "for group in vis_group_by_q_movie:\n",
    "    data_target_list = data_target_list + list(itertools.product([group['g_id']], group['g_movies']))\n",
    "y=[]\n",
    "data_X = []\n",
    "\n",
    "#print(data_target_list)\n",
    "\n",
    "for pair in data_target_list:\n",
    "    title = helper_fn.find_movie_title_by_id(pair[0],train_data_df)\n",
    "    y.append(title.values[0].capitalize())\n",
    "    data_X.append(pair[1])\n",
    "\n",
    "data_X_vec = [model[tag] for tag in data_X]\n",
    "tsne=  TSNE(perplexity= 5, n_components=2, init='pca', n_iter=5000, random_state=23)\n",
    "tsne_obj= tsne.fit_transform(data_X_vec)\n",
    "tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                        'Y':tsne_obj[:,1],\n",
    "                        'movie':y})\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "g=sns.scatterplot(x=\"X\", y=\"Y\",\n",
    "              hue=\"movie\",\n",
    "              palette=['purple','red','orange','brown','blue',\n",
    "                       'dodgerblue','green','lightgreen','darkcyan', 'black'],\n",
    "              legend='full',\n",
    "              data=tsne_df);\n",
    "plt.title('Model generated movies with similarity')\n",
    "g.figure.savefig(\"generated_simialr_movies.png\")\n",
    "\n",
    "g.legend(loc='center left', bbox_to_anchor=(1.00, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(col):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#further analysis to the results in visualizing the 10 movies and their simialr ones\n",
    "#get list of genres for each group\n",
    "\n",
    "all_group_genres_list = []\n",
    "for group in vis_group_by_q_movie: \n",
    "    group_genres_list=[]\n",
    "    id_genres_list = []\n",
    "    #genres for the query movie\n",
    "    movie_genres = helper_fn.find_movie_genre_by_id(group['g_id'], train_data_df)\n",
    "    id_genres_list = id_genres_list + movie_genres.to_list()[0]\n",
    "    \n",
    "    for movie_id in group['g_movies']:\n",
    "        movie_genres = helper_fn.find_movie_genre_by_id(movie_id, train_data_df)\n",
    "        group_genres_list = group_genres_list + movie_genres.tolist()[0]\n",
    "     #   print(group_genres_list[0])\n",
    "    g_genres={'g_id':group['g_id'], 'q_genres':id_genres_list,'g_genres': list(set(group_genres_list))}\n",
    "    all_group_genres_list.append(g_genres)\n",
    "\n",
    "group_genres_df = pd.DataFrame(data= {'movie_id':[g['g_id'] for g in all_group_genres_list]\n",
    "                                      ,'q_genres':[g['q_genres'] for g in all_group_genres_list]\n",
    "                                      ,'genres_list':[g['g_genres'] for g in all_group_genres_list]})\n",
    "\n",
    "group_genres_df['q_genres'] = group_genres_df.apply(lambda row: '|'.join(row['q_genres']), axis=1)\n",
    "group_genres_df['genres_list'] = group_genres_df.apply(lambda row: '|'.join(row['genres_list']), axis=1)\n",
    "display(tabulate(group_genres_df, headers=['Query Movie', \"Query Movie Genres\", \"Similar movies genres\"],tablefmt='html', showindex=False))\n",
    "group_genres_df.to_excel(\"models/exp1/sim_gen_list.xlsx\", index=False)\n",
    "#group_genres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the ranking score for a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare test data\n",
    "test_titles = []\n",
    "test_titles= ['shrek','star trek','blade','toy story 4','pitch perfect','harry potter','godzilla','paddington','x-men']\n",
    "test_data= eval_fn.build_movie_sequel_test_data(train_data_df, test_titles)\n",
    "\n",
    "rank_score_list = eval_fn.calculate_rank_score(model,test_data,5)\n",
    "group_rank_df = pd.DataFrame(data= {'group_id':[g['group_id'] for g in rank_score_list], 'score':[g['group_score'] for g in rank_score_list]})\n",
    "group_rank_df.append(group_rank_df.sum(numeric_only=True), ignore_index=True)\n",
    "group_rank_df.loc['Column_Total']= group_rank_df.sum(numeric_only=True, axis=0)\n",
    "group_rank_df.iloc[len(group_rank_df)-1].group_id= \"Total\"\n",
    "\n",
    "display(tabulate(group_rank_df, headers=['Group', \"Rank Score\"],tablefmt='html', colalign=(\"right\", \"left\"),showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate model BLEU score\n",
    "test_titles = []\n",
    "test_titles= ['shrek','star trek','blade','toy story 4','pitch perfect','harry potter','godzilla','paddington','x-men']\n",
    "test_data= eval_fn.build_movie_sequel_test_data(train_data_df, test_titles)\n",
    "bleu_score = eval_fn.calculate_model_bleu_score(model, test_data, train_data_df, 5)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vis_genres_sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize movies by genre\n",
    "#genres_sample_df contains movies from the genres 'Romantic_Comedy','Drama','Adventure','Crime','Action','Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "data_X = []\n",
    "\n",
    "#print(data_target_list)\n",
    "\n",
    "\n",
    "\n",
    "vis_genres_sample_df = genres_sample_df.copy()\n",
    "\n",
    "vis_genres_sample_df['data_X_vec']= vis_genres_sample_df.apply(lambda movie:model[movie.movie_id], axis=1)\n",
    "vis_genres_sample_df['y']= vis_genres_sample_df.apply(lambda movie: assign_genre(genres_df, movie.movie_id), axis=1)\n",
    "\n",
    "data_X_vec = list(vis_genres_sample_df['data_X_vec'].values)\n",
    "y = vis_genres_sample_df['y']\n",
    "tsne=  TSNE(perplexity= 5, n_components=2, init='pca', n_iter=5000, random_state=23)\n",
    "tsne_obj= tsne.fit_transform(data_X_vec)\n",
    "tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                        'Y':tsne_obj[:,1],\n",
    "                        'movie':y})\n",
    "tsne_df.head()\n",
    "sns.scatterplot(x=\"X\", y=\"Y\",\n",
    "              data=tsne_df);\n",
    "\n",
    "g=sns.scatterplot(x=\"X\", y=\"Y\",\n",
    "              hue=\"movie\",\n",
    "         #     palette=['purple','red','orange','brown','blue','black'],\n",
    "              legend='full',\n",
    "              data=tsne_df);\n",
    "plt.title('Movies grouped by genre ')\n",
    "g.legend(loc='center left', bbox_to_anchor=(1.00, 0.5), ncol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot sequelmovies with some noise data with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot_doc2vec(model, samples,movies_dict,height, width):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "    \n",
    "\n",
    "    for doc in samples:\n",
    "        tokens.append(model[doc])\n",
    "        labels.append(movies_dict[doc])\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(height, width)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "   # plt.ylim(1, -7)\n",
    "   # plt.xlim(-7,-1)\n",
    "    \n",
    "    \n",
    "    plt.title('Similar and non-similar movies')\n",
    "    plt.show()\n",
    "    #plt.figimage.savefig('movies_labels_large.png',  bbox_inches='tight')\n",
    "    plt.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_doc2vec(model, sequel_sampled_data_df.movie_id,movies_dict,10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not sure what is this for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot_doc2vec_categorized(model, samples,movies_dict, w,h):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "    colors = []\n",
    "    \n",
    "\n",
    "    for doc in samples:\n",
    "        tokens.append(model[doc])\n",
    "        labels.append(movies_dict[doc])\n",
    "        colors.append(assign_color(genres_df, doc))\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=50, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(w, h)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i],color= colors[i][0] )\n",
    "        plt.annotate('', #labels[i],\n",
    "                     xy=(x[i], y[i], ),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "   # plt.xlim(-4.0, -1.0)\n",
    "  #  display(HTML(\"<b>%d words most similar to '%s'</b>\" % (n,word)))\n",
    "    plt.title('Movies Distribution by Genre')\n",
    "    plt.legend( labels=['Romantic_Comedy','Drama','Adventure','Crime','Action','Unknown'])\n",
    "    plt.savefig('movies_genre.png')\n",
    "   # plt.show(block=False)\n",
    "    plt.show()\n",
    "genres_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_doc2vec_categorized(model, set(genres_sample_df[0:100].movie_id), movies_dict, 12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_samples= genres_sample_df.movie_id.values.tolist()\n",
    "len(genre_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_data=train_data_df[col_name]\n",
    "val_list=[]\n",
    "for data in col_data:\n",
    "    for val in data:\n",
    "        val_list.append(val)\n",
    "occurence_count = Counter(val_list)\n",
    "high_cnt = occurence_count.most_common(10)[0:10]\n",
    "x= [cnt[0] for cnt in high_cnt ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_doc2vec(model, set(genre_samples[0:100]), movies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot movies by features\n",
    "\n",
    "def plot_movies_by_feature(col_name, train_data_df, sample_size):\n",
    "    col_data=train_data_df[col_name]\n",
    "    val_list=[]\n",
    "    for data in col_data:\n",
    "        for val in data:\n",
    "            val_list.append(val)\n",
    "\n",
    "    occurence_count = Counter(val_list)\n",
    "    print(len(occurence_count))\n",
    "    high_cnt = occurence_count.most_common(sample_size)[0:sample_size]\n",
    "    val_list= [cnt[0] for cnt in high_cnt ]\n",
    "    print(val_list)\n",
    "    \n",
    "    movies_val_dict={}\n",
    "\n",
    "    #val_list = random.sample(val_list,sample_size)\n",
    "    for val in val_list:\n",
    "        movies_val_dict[val] = helper_fn.find_movies_by_col_value(col_name, val, train_data_df)    \n",
    "    \n",
    "    data_target_list=[]\n",
    "    for key in val_list:\n",
    "        for val in movies_val_dict[key]:\n",
    "            data_target_list.append((key,val))\n",
    "    y=[]\n",
    "    data_X = []\n",
    "\n",
    "    for pair in data_target_list:\n",
    "        y.append(pair[0])\n",
    "        data_X.append(pair[1])\n",
    "\n",
    "    data_X_vec = [model[tag] for tag in data_X]\n",
    "    sns.set_context('notebook')\n",
    "    tsne=  TSNE(perplexity= 50, n_components=2, init='pca', n_iter=5000, random_state=23)\n",
    "    tsne_obj= tsne.fit_transform(data_X_vec)\n",
    "    tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                        'Y':tsne_obj[:,1],\n",
    "                        col_name:y})\n",
    "    return tsne_df\n",
    "\n",
    "def draw_plot(tsne_df, col_name, title,filename):\n",
    "   # sns.set_palette(sns.color_palette(\"default\", 20))\n",
    "    #sns.color_palette()\n",
    "    tsne_df[col_name] = tsne_df[col_name].apply(lambda c: c[1:] if c.startswith('_') else c)\n",
    "    g=sns.scatterplot(x=\"X\", y=\"Y\",\n",
    "                  hue=col_name,\n",
    "              #    hue_order= cat_order,\n",
    "                #  palette=['purple','red','orange'],\n",
    "                  legend= 'full',            \n",
    "                  data=tsne_df);\n",
    "    \n",
    "    g.set_title(title)\n",
    "    #g.set_xlim(-600, 800)\n",
    "    #g.set_ylim(-800, 600)\n",
    "    g.legend(loc='center left', bbox_to_anchor=(1.00, 0.5), ncol=1)\n",
    "    g.figure.savefig(filename)\n",
    "    plt.close\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size= 5\n",
    "#col_name= 'actor_name' #10 actors\n",
    "#col_name='writer_name' #10 samples\n",
    "#col_name='director_name' #10\n",
    "#col_name='country' #10 samples\n",
    "#col_name='genre' #top 10\n",
    "\n",
    "plot_df = plot_movies_by_feature(col_name,train_data_df, sample_size)\n",
    "title= \"Movies grouped by \"+col_name\n",
    "filename= col_name+\"_plot.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_plot(plot_df,col_name, title,filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_closest_line(similar_movies, query_movie, n):\n",
    "   # display(html.HTML(\"<b>%d words most similar to '%s'</b>\" % (n, query_movie)))\n",
    "    \n",
    "    tops = similar_movies\n",
    "    \n",
    "    items = [item[0] for item in tops]\n",
    "    sims = [item[1] for i,item in enumerate(tops)]\n",
    "    \n",
    "    fig = plt.figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    \n",
    "    plt.xticks(range(n), [i+1 for i in range(n)])\n",
    "    plt.xlabel('Rank')\n",
    "    plt.ylabel('Similarity')\n",
    "    plt.xlim(-1,n)\n",
    "\n",
    "    \n",
    "    ax.plot(sims, color=\"purple\", alpha=0.5)\n",
    "    \n",
    "    for item, x, y in zip(items, range(n), sims):\n",
    "        ax.annotate( item, xy=(x, y), xytext=(20, -7), textcoords='offset points', \n",
    "                     ha='right', va='bottom', color='orange', fontsize=14 )\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
