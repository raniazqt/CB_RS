{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your movie title to search or 'quit/q' to exit:  yuyi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for movies similar to yuyi\n",
      "movie yuyi was not found. Retrieve movie information from LOD\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['actor_name', 'country', 'director_name'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e076116db388>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-e076116db388>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_movie_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"movie {} was not found. Retrieve movie information from LOD\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_movie_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                 \u001b[0mquery_movie_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrieve_features_from_lod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_movie_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_movie_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e076116db388>\u001b[0m in \u001b[0;36mretrieve_features_from_lod\u001b[1;34m(movie_title)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mresult_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mselect_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountry_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountry_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mresult_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'movie_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'actor_name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'director_name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'writer_name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2910\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2912\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python39\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['actor_name', 'country', 'director_name'] not in index\""
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: latin-1 -*-\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import csv\n",
    "import logging\n",
    "from SPARQLWrapper import SPARQLWrapper,JSON, SPARQLWrapper2, POST,XML,GET\n",
    "import query_helper_functions as q_helper\n",
    "import sparql_query as sparql_query\n",
    "import movies_df_helper_functions as d_helper\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import re\n",
    "import imp\n",
    "imp.reload(q_helper)\n",
    "imp.reload(d_helper)\n",
    "imp.reload(sparql_query)\n",
    "\n",
    "from os import system, name \n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def select_values(to_keep_val, other_val):\n",
    "    if (str(to_keep_val) != \"NOT_FOUND\"):\n",
    "        return to_keep_val\n",
    "    else:\n",
    "        return other_val\n",
    "\n",
    "#retrieves movie features from lod (dbpedia and yago)\n",
    "def retrieve_features_from_lod(movie_title):\n",
    "    dbpedia_results= query_dbpedia_by_title(movie_title)\n",
    "    yago_results = query_yago_by_title(movie_title)\n",
    "    \n",
    "    yago_results= yago_results.fillna(\"NOT_FOUND\")\n",
    "    #group yago results\n",
    "    yago_grouped = yago_results.groupby(['movie_id','title'], as_index=False)\n",
    "    yago_info_df = yago_grouped.agg({\n",
    "                                        'director_name':lambda x: '|'.join(set(x)),\n",
    "                                        'genre':lambda x: '|'.join(set(x)),                                      \n",
    "                                        'country':lambda x:  '|'.join(set(x)),\n",
    "                                        'actor_name':lambda x: '|'.join(set(x))\n",
    "                                        })\n",
    "    #Group pedia results\n",
    "    dbpedia_results= dbpedia_results.fillna(\"NOT_FOUND\")\n",
    "    dbpedia_grouped = dbpedia_results.groupby(['movie_id','title'], as_index=False)\n",
    "    dbpedia_info_df = dbpedia_grouped.agg({\n",
    "                                        'director_name':lambda x:  '|'.join(set(x)),\n",
    "                                        'writer_name':lambda x: '|'.join(set(x)),                                      \n",
    "                                        'country':lambda x: '|'.join(set(x)),\n",
    "                                        'actor_name':lambda x: '|'.join(set(x))\n",
    "                                        })\n",
    "    result_df = yago_info_df.merge(dbpedia_info_df, how=\"inner\", on=['movie_id','title'])\n",
    "    if len(result_df) >0:\n",
    "        #keep dbpedia value if both exist\n",
    "        result_df['actor_name'] = result_df.apply(lambda row: select_values(row.actor_name_y, row.actor_name_x), axis=1)\n",
    "        #keep director from yago if exists in both\n",
    "        result_df['director_name'] = result_df.apply(lambda row: select_values(row.director_name_x, row.director_name_y), axis=1)\n",
    "        #keep director from yago if exists in both\n",
    "        result_df['country'] = result_df.apply(lambda row: select_values(row.country_x, row.country_y), axis=1)\n",
    "    \n",
    "        result_df = result_df[['movie_id','title','actor_name','director_name','writer_name','country','genre']].copy()\n",
    "    \n",
    "    print(result_df)\n",
    "    return result_df\n",
    "\n",
    "def query_dbpedia_by_title(query_movie_title):\n",
    "    endpoint = \"https://dbpedia.org/sparql\"\n",
    "    return_format = XML\n",
    "    request_method= POST\n",
    "    query = sparql_query.dbpedia_query_by_title\n",
    "    query_title_list ='\\\"\"\"' + '\\\"\"\",\\\"\"\"' + query_movie_title.lower() + '\\\"\"\"' \n",
    "    q_results= q_helper.execute_query_for_movies_list(query, query_title_list,endpoint,return_format,request_method)\n",
    "    q_results_df= q_helper.get_sparql_dataframe(q_results)\n",
    "    return q_results_df\n",
    "\n",
    "def query_yago_by_title(query_movie_title):\n",
    "    endpoint=\"https://yago-knowledge.org/sparql/query\"\n",
    "    return_format = JSON\n",
    "    request_method= POST\n",
    "    query = sparql_query.yago_query_by_title\n",
    "    query_title_list ='\\\"\"\"' + '\\\"\"\",\\\"\"\"' + query_movie_title.lower() + '\\\"\"\"' \n",
    "    q_results= q_helper.execute_query_for_movies_list(query, query_title_list,endpoint,return_format,request_method)\n",
    "    q_results_df= q_helper.get_sparql_dataframe(q_results)\n",
    "    return q_results_df\n",
    "\n",
    "def get_movie_sentence(movie_df):\n",
    "        movie_df = movie_df.replace(\"NOT_FOUND\",None)\n",
    "        movie_df = data_processing(movie_df, 'actor_name')\n",
    "        movie_df = data_processing(movie_df, 'writer_name')\n",
    "        movie_df = data_processing(movie_df, 'genre')\n",
    "        movie_df = data_processing(movie_df, 'country')\n",
    "        movie_df = data_processing(movie_df, 'director_name')\n",
    "        movie_df['movie_id']=movie_df['movie_id'].str.lower()\n",
    "        movie_df['title']=movie_df['title'].str.lower()\n",
    "        movie_df['movie_sentence']= movie_df.apply(lambda row:  build_movie_sentence(row.actor_name, row.director_name, row.writer_name, row.genre, row.country), axis=1)\n",
    "        return movie_df['movie_sentence'].to_list()             \n",
    "\n",
    "def find_similar_movie(movie_sent):\n",
    "    model = Doc2Vec.load('models/exp3/model')\n",
    "    model.infer_vector(movie_sentence)\n",
    "    \n",
    "def print_sim_list(sim_list):\n",
    "    print(tabulate(sim_list, headers= ['Movie ID', 'Similarity']))\n",
    "    \n",
    "def data_processing(df, col_name):    \n",
    "    regex = \"\\(.*?\\)\"\n",
    "    df[col_name] = df[col_name].apply(lambda \n",
    "                                      row: re.sub(regex,'',row) if row != None  else row)\n",
    "    df[col_name] = df[col_name].apply(lambda row: \n",
    "                                      row.lower().strip().replace(' ','_').split('|') if row != None   else row)\n",
    "    df[col_name] = df[col_name].apply(lambda \n",
    "                                      row: [item.strip() for item in row] if row != None   else row)\n",
    "    return df\n",
    "\n",
    "def build_movie_sentence(actor,director,writer,genre,country):\n",
    "    sent= []\n",
    "    if actor != None:\n",
    "        sent = sent + actor\n",
    "    if director != None:\n",
    "        sent = sent + director\n",
    "    if writer != None:\n",
    "        sent = sent + writer\n",
    "    if genre != None:\n",
    "        sent = sent + genre\n",
    "    if country != None:\n",
    "        sent = sent + country\n",
    "    return sent\n",
    "\n",
    "def isNaN(string):\n",
    "    return string != string\n",
    "\n",
    "#**************************************************************************************************\n",
    "\n",
    "def main():\n",
    "    query_movie_title = \"enter\"\n",
    "    train_data_df = pd.read_csv('train_data.csv')\n",
    "    model = Doc2Vec.load('model')\n",
    "    headers=['Actor','Director', 'Writer', 'Genre', 'Country']\n",
    "    while (query_movie_title != quit):\n",
    "        query_movie_title = \"\"\n",
    "        \n",
    "        query_movie_title = input(\"Enter your movie title to search or 'quit/q' to exit: \") \n",
    "        if (len(query_movie_title)==0):\n",
    "            print(\"Empty input! please try again\")\n",
    "        else:\n",
    "            system('cls') \n",
    "            if query_movie_title.lower() in ['quit','q']:\n",
    "                break;\n",
    "\n",
    "\n",
    "            print(\"Searching for movies similar to {}\".format(query_movie_title))\n",
    "\n",
    "            #Search for movie title in the current training data.\n",
    "            #if found, retrieve movie_id\n",
    "            #if not found, query LOD for the movie features\n",
    "            query_movie_id = d_helper.find_movie_id_by_title(query_movie_title, train_data_df)\n",
    "\n",
    "            if len(query_movie_id) == 0:    \n",
    "                print(\"movie {} was not found. Retrieve movie information from LOD\".format(query_movie_title))    \n",
    "                query_movie_df = retrieve_features_from_lod(query_movie_title)\n",
    "\n",
    "                if len(query_movie_df) >0:\n",
    "                    print(\"Movie deatils found! \")\n",
    "                    query_movie_df['genre']=None\n",
    "\n",
    "                    print(tabulate(query_movie_df[['actor_name','director_name','writer_name','genre','country']], headers= headers))\n",
    "\n",
    "                    movie_sentence = get_movie_sentence(query_movie_df) \n",
    "                    movie_sentence= movie_sentence[0]\n",
    "                    infer_vector = model.infer_vector(movie_sentence)\n",
    "                    sim_list= model.docvecs.most_similar([infer_vector])\n",
    "\n",
    "                else:\n",
    "                    print(\"Movies details were not found!! Try different movie\")\n",
    "            else:\n",
    "                print(\"movie {} was found in local database. Searching for similar movie\".format(query_movie_title))\n",
    "                sim_list = model.docvecs.most_similar(query_movie_id)\n",
    "\n",
    "            if len(sim_list) == 0 :\n",
    "                 print(\"Error finding similar movie! please try again.\")\n",
    "            else:\n",
    "                print_sim_list(sim_list)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-05 21:33:58,502 : INFO : loading Doc2Vec object from model\n",
      "2020-12-05 21:33:58,620 : INFO : loading vocabulary recursively from model.vocabulary.* with mmap=None\n",
      "2020-12-05 21:33:58,620 : INFO : loading trainables recursively from model.trainables.* with mmap=None\n",
      "2020-12-05 21:33:58,620 : INFO : loading wv recursively from model.wv.* with mmap=None\n",
      "2020-12-05 21:33:58,620 : INFO : loading docvecs recursively from model.docvecs.* with mmap=None\n",
      "2020-12-05 21:33:58,621 : INFO : loaded model\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your movie title to search or 'quit/q' to exit:  q\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
