{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: latin-1 -*-\n",
    "import pandas as pd # pandas is a data manipulation library\n",
    "import numpy as np #provides numerical arrays and functions to manipulate the arrays efficiently\n",
    "import logging\n",
    "import difflib\n",
    "import Levenshtein as lev\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import re\n",
    "import movies_df_helper_functions as fn\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "tqdm.pandas(desc=\"my bar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movies.csv\n",
    "movies_file_df = pd.read_csv('generated_dataset/final_movies_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_file_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_file_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_file_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_file_df.describe(include=['object', 'bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************Prepare the movies information to be used for training the doc2vec model ***********************\n",
    "\\rnsteps:\n",
    "Step 1-split actor_name, director_name,writer_name,genere_id,country_id and convert it to list of words\n",
    "#Step 2-concatenate first and last names with an _\n",
    "#Step 3.convert all data to lower case\n",
    "#Step 4-concatenate movie_id and title to overcome the issue of movies having the same title\n",
    "#Step 5-create a sentence to represent each movie by combining all attributes for every movie in one string with space separating each value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#copy data into new dataframe\n",
    "movies_df = movies_file_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#replace not_found with null\n",
    "movies_df.replace(['NOT_FOUND'], [None], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_processing(df, col_name):    \n",
    "    regex = \"\\(.*?\\)\"\n",
    "    df[col_name] = df[col_name].apply(lambda row: re.sub(regex,'',row) if row is not None else row)\n",
    "    df[col_name] = df[col_name].apply(lambda row: row.lower().strip().replace(' ','_').split('|') if row is not None else row)\n",
    "    df[col_name] = df[col_name].apply(lambda row: [item.strip() for item in row] if row is not None else row)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regex = \"\\(.*?\\)\"\n",
    "#movies_df.actor_name = movies_df.actor_name.apply(lambda row: re.sub(regex,'',row) if row is not None else row)\n",
    "#movies_df.director_name = movies_df.director_name.apply(lambda row:  re.sub(regex,'',row)  if row is not None else row)\n",
    "#movies_df.writer_name = movies_df.writer_name.apply(lambda row:  re.sub(regex,'',row)  if row is not None else row)\n",
    "#movies_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data_processing() missing 1 required positional argument: 'regex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-f2ebb15844a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mregex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\(.*?\\)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmovies_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'actor_name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmovies_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'writer_name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmovies_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'genre_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmovies_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'country_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data_processing() missing 1 required positional argument: 'regex'"
     ]
    }
   ],
   "source": [
    "regex = \"\\(.*?\\)\"\n",
    "movies_df = data_processing(movies_df, 'actor_name')\n",
    "movies_df = data_processing(movies_df, 'writer_name')\n",
    "movies_df = data_processing(movies_df, 'genre_id')\n",
    "movies_df = data_processing(movies_df, 'country_id')\n",
    "movies_df = data_processing(movies_df, 'director_name')\n",
    "movies_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create movie id by extracting the dbpedia movie id from the link\n",
    "movies_df['movie_id']= movies_df['movie'].str.split('http://dbpedia.org/resource/').str[1]\n",
    "movies_df['movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df['movie_id']=movies_df['movie_id'].str.lower()\n",
    "movies_df['title']=movies_df['title'].str.lower()\n",
    "movies_df[['movie_id','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df.iloc[0]\n",
    "#movies_df.iloc[0].movie_sentence = [] + [] + ['lynn_hershman_leeson'] +['Unites_States'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#create movie sentence with movies attributes; actors, writers,directors,genre,country\n",
    "#code is not working DON'T know WHYYYY\n",
    "#movies_df['movie_sentence']= movies_df.apply(lambda row: row['movie_sentence']\n",
    "#                            +[] if row['actor_name'] is None else row['actor_name'] \n",
    "#                            + [] if row['genre_id'] is None else row['genre_id']\n",
    "#                            + [] if row['director_name'] is None else row['director_name']\n",
    "#                            + [] if row['writer_name'] is None else row['writer_name']\n",
    "#                            + [] if row['country_id'] is None else row['country_id']                 \n",
    "#                  , axis=1)\n",
    "                  \n",
    "\n",
    "#movies_df[\"movie_sentence\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df['movie_sentence'] = movies_df.progress_apply(lambda row:  fn.build_sentence_from_col(row.actor_name, row.genre_id, row.director_name, row.writer_name, row.country_id), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df[movies_df['movie_sentence'].str.len() == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df['movie_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df.to_csv('generated_dataset/dpedia_yago_doc2vec_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ********************************* Create the doc2vec model **********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the tagged document needed for Doc2Vec\n",
    "tagged_documents=[]\n",
    "movies_df.progress_apply(lambda row : tagged_documents.append(TaggedDocument(row.movie_sentence,[row.movie_id])),axis=1)\n",
    "\n",
    "#convert the series of tagged docuemnt to a list\n",
    "train_data = list(tagged_documents)\n",
    "\n",
    "print(\"Length of training data {}\".format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed = 400\n",
    "[random.shuffle(data.words) for data in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Configure and train the model\n",
    "model = gensim.models.doc2vec.Doc2Vec(dm= 0, vector_size= 70, sample= 0, window= 5, min_count=1, workers=cores, epochs= 100)\n",
    "model.build_vocab(train_data)\n",
    "model.train(train_data, total_examples=len(train_data) , epochs=model.epochs)\n",
    "#save the model\n",
    "model.save(\"models/exp4/model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
